# NLP-Tokenization
Here i have tried to understand and tokenize a paragraph
Tokenization is the process in which we split a paragraph/sentence into single words, these small words are called tokens

#Process and library 
- NLTK is an important library for Natural Language processing
- we use Punkt package: Punkt Sentence Tokenizer. This tokenizer divides a text into a list of sentences, by using an unsupervised algorithm to build a model for abbreviation words, collocations, and words that start sentences. It must be trained on a large collection of plaintext in the target language before it can be used.

